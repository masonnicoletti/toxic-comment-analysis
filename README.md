# Toxic Comment Analysis
DS 4021 Final Project

Dongju Han, Kayla Kim, Mason Nicoletti

## Introduction:

Social media harm is a pervasive issue, driven by the rapid spread of toxic comments, hate speech, and polarized discourse across online platforms. As part of Data Project 3, the team collected and analyzed large-scale Bluesky Firehose data, accessible in the project repository under the skyblue directory: [Skyblue Directory](https://github.com/djhan0330/ds3022-data-project-3/tree/main/skyblue)


Through this exploratory analysis, the team identified patterns and linguistic features indicative of harmful online content. To study these patterns rigorously, the project applies a range of machine-learning methods for sentiment and toxicity classification, including Support Vector Machines (SVM), logistic regression, ensemble methods such as Random Forest, and neural networks. By comparing the performance of these models, the analysis aims to provide deeper insight into how toxic speech manifests within social media data and which approaches are most effective at detecting harmful content at scale.

## Origin of dataset:
From Jigsaw competition in Kaggle. A dataset of Reddit comments and sentiment analysis metadata:
https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/data

- the test and training sets from the competition are within zip files under the data/ folder of this repository
