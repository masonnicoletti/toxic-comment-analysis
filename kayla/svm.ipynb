{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1bee7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "from data_cleaning import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66aae2a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['split', 'created_date', 'publication_id', 'parent_id', 'article_id', 'male', 'female', 'transgender', 'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity', 'physical_disability', 'intellectual_or_learning_disability', 'psychiatric_or_mental_illness', 'other_disability', 'identity_annotator_count'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m train_clean \u001b[38;5;241m=\u001b[39m clean_data(train_raw)\n\u001b[1;32m      4\u001b[0m train_clean\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/train_clean.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#test\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/toxic-comment-analysis/kayla/../scripts/data_cleaning.py:39\u001b[0m, in \u001b[0;36mclean_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_data\u001b[39m(df):\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Drop columns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     drop_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity_annotator_count\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# not sure if this variable is useful for us\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     ]\n\u001b[0;32m---> 39\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(drop_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Drop NA Comments\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5264\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5400\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5401\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5402\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5403\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5404\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5405\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5406\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5407\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['split', 'created_date', 'publication_id', 'parent_id', 'article_id', 'male', 'female', 'transgender', 'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity', 'physical_disability', 'intellectual_or_learning_disability', 'psychiatric_or_mental_illness', 'other_disability', 'identity_annotator_count'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_raw = pd.read_csv(\"../data/train.csv\")\n",
    "train_clean = clean_data(train_raw)\n",
    "train_clean.to_csv(\"../data/train_clean.csv\", index=False)\n",
    "\n",
    "#test\n",
    "test_raw = pd.read_csv(\"../data/test.csv\")\n",
    "test_clean = clean_data(test_raw)\n",
    "test_clean.to_csv(\"../data/test_clean.csv\", index=False)\n",
    "\n",
    "print(\"Saved train_clean.csv and test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_clean.csv')\n",
    "# df = pd.read_csv('../data/train.csv') # when running just the clean script instead of ./clean_scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e6a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.714286\n",
      "3    0.000000\n",
      "4    0.000000\n",
      "Name: toxicity, dtype: float64\n",
      "\n",
      "\n",
      "Index(['comment_text', 'funny', 'wow', 'sad', 'likes', 'disagree', 'toxicity',\n",
      "       'severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack',\n",
      "       'insult', 'threat', 'toxicity_annotator_count', 'rating_rejected'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "0.0 1.0\n",
      "0 That was the reason Walker fire everyone now what ?.\n",
      "1 So my original statement still stands . A church needs to not get involved in supporting Candidate A as opposed to Candidate B, it must however must make a stand on the side of the Gospel and help its congregation be informed and allow it to vote on that basis...\n",
      "2 All you ever do is come to these forums berating white people with your Critical Race Theory garbage.\n",
      "\n",
      "Please study Islamic Law before stupidly comparing someone you speculate is fueled by a verboten emotion to ISIS. \n",
      "\n",
      "Good grief, study something more than CRT.\n",
      "3 Tonight will be an excellent opportunity for Clayton Kershaw to show that his bad postseason reputation is exaggerated, a bad rap. In his two postseason starts this year, his ERA is 4.76. He has also given up 5 HRs. After a superb August, Kershaw's ERA in September was 3.48, not terrible, but not up to his overall season performance. Simply put, Kershaw has not been overpowering for a while, and he's been susceptible to the long ball. But he can change all that tonight.\n",
      "\n",
      "Also of note, Clayton Kershaw has an opt out clause in his contract at the end of 2018. Probably not many Dodger fans are thinking about that today, but tonight's game may resonate down the road as that approaches, one way or the other.\n",
      "4 I read about this on Stars and Stripes oversea and I couldn't understand why the lake became an ocean. But after visiting Skilak Lake for the first time about 12 years after the event, I really could understand why such a tragic event took place.\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "\n",
    "print(df['toxicity'].head())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(np.min(df['toxicity']), np.max(df['toxicity']))\n",
    "\n",
    "\n",
    "for idx, text in df[\"comment_text\"].head(5).items():\n",
    "    print(idx, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd5d91",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "584e0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making label of toxicity feature into binary from continuous (0.0 to 1.0)\n",
    "\n",
    "df[\"comment_text\"] = df[\"comment_text\"].fillna(\"\").astype(str)\n",
    "df[\"label\"] = (df[\"toxicity\"] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09efc0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in cleaned df: ['comment_text', 'funny', 'wow', 'sad', 'likes', 'disagree', 'toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack', 'insult', 'threat', 'toxicity_annotator_count', 'rating_rejected', 'label']\n",
      "Numeric feature columns (first few): ['funny', 'wow', 'sad', 'likes', 'disagree', 'severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack', 'insult']\n"
     ]
    }
   ],
   "source": [
    "# chosen columns\n",
    "# cols = ['rating', 'funny', 'wow', 'sad', 'likes',\n",
    "#        'disagree', 'sexual_explicit',\n",
    "#        'male', 'female', 'transgender',\n",
    "#        'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
    "#        'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
    "#        'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
    "#        'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
    "#        'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
    "#        'other_disability']\n",
    "\n",
    "text_col = \"comment_text\"\n",
    "y = df[\"label\"]\n",
    "\n",
    "cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in [text_col, \"label\", \"toxicity\"]\n",
    "]\n",
    "\n",
    "# df[cols] = df[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "# df[cols] = df[cols].fillna(0)\n",
    "\n",
    "print(\"Columns in cleaned df:\", df.columns.tolist())\n",
    "print(\"Numeric feature columns (first few):\", cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f569e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(\n",
    "    df.index,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22e95ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[\"label\"].loc[train_idx]\n",
    "y_val = df[\"label\"].loc[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ca844",
   "metadata": {},
   "source": [
    "### Just text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6de85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split (already done in data_prep.py and data_cleaning.py in ./scripts)\n",
    "X_train_text = df.loc[train_idx, \"comment_text\"]\n",
    "X_val_text   = df.loc[val_idx, \"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39adf29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464170270456871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    293147\n",
      "           1       0.75      0.49      0.59     25499\n",
      "\n",
      "    accuracy                           0.95    318646\n",
      "   macro avg       0.86      0.74      0.78    318646\n",
      "weighted avg       0.94      0.95      0.94    318646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# just LinearSVC with text in X_train or X_test\n",
    "clf_text = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer( # strings to numeric\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=5,\n",
    "        max_df=0.9\n",
    "    )),\n",
    "    (\"svm\", LinearSVC(random_state=42)) # regular linearSVC algorithm\n",
    "])\n",
    "\n",
    "clf_text.fit(X_train_text, y_train)\n",
    "y_pred_text = clf_text.predict(X_val_text)\n",
    "\n",
    "print(accuracy_score(y_val, y_pred_text))\n",
    "print(classification_report(y_val, y_pred_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee326f46",
   "metadata": {},
   "source": [
    "### Other columns and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a3e3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_both = df.loc[train_idx, [\"comment_text\"] + cols]\n",
    "X_val_both   = df.loc[val_idx, [\"comment_text\"] + cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c25c7f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaylakim/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824256384828305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    293147\n",
      "           1       0.90      0.87      0.89     25499\n",
      "\n",
      "    accuracy                           0.98    318646\n",
      "   macro avg       0.95      0.93      0.94    318646\n",
      "weighted avg       0.98      0.98      0.98    318646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC with text and other columns\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(\n",
    "            stop_words=\"english\",\n",
    "            ngram_range=(1, 2)\n",
    "        ), \"comment_text\"),\n",
    "        (\"num\", StandardScaler(), cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf_both = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"svm\", LinearSVC(random_state=42))\n",
    "])\n",
    "\n",
    "clf_both.fit(X_train_both, y_train)\n",
    "y_pred_both = clf_both.predict(X_val_both)\n",
    "\n",
    "print(accuracy_score(y_val, y_pred_both))\n",
    "print(classification_report(y_val, y_pred_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110c3d0",
   "metadata": {},
   "source": [
    "### Just other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a066f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = df.loc[train_idx, cols]\n",
    "X_val_num   = df.loc[val_idx, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c03b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98381275773115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    293147\n",
      "           1       0.90      0.90      0.90     25499\n",
      "\n",
      "    accuracy                           0.98    318646\n",
      "   macro avg       0.95      0.94      0.94    318646\n",
      "weighted avg       0.98      0.98      0.98    318646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC withOUT text and just other columns\n",
    "clf_num = Pipeline([\n",
    "    (\"ss\", StandardScaler()),\n",
    "    (\"svm\", LinearSVC(random_state=42))\n",
    "])\n",
    "\n",
    "clf_num.fit(X_train_num, y_train)\n",
    "y_pred_num = clf_num.predict(X_val_num)\n",
    "\n",
    "print(accuracy_score(y_val, y_pred_num))\n",
    "print(classification_report(y_val, y_pred_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817917d0",
   "metadata": {},
   "source": [
    "## Optimizing just Both Comment and Columns SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3be151db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proprocess and pipeline build\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(\n",
    "            stop_words=\"english\"\n",
    "        ), \"comment_text\"),\n",
    "        (\"num\", StandardScaler(), cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_svm_both = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"svm\", LinearSVC(random_state=42, max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e5d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for combined model\n",
    "param_grid_both = {\n",
    "    \"preprocess__text__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"preprocess__text__min_df\": [2, 5, 10],\n",
    "    \"svm__C\": [0.1, 1, 5]\n",
    "}\n",
    "\n",
    "# actual optimization through GridSearchCV\n",
    "grid_both = GridSearchCV(\n",
    "    estimator=base_svm_both,\n",
    "    param_grid=param_grid_both,\n",
    "    cv=3, \n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# X_train_both and y_train from  unified split\n",
    "grid_both.fit(X_train_both, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0391d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (combined SVM): {'preprocess__text__min_df': 10, 'preprocess__text__ngram_range': (1, 1), 'svm__C': 1}\n",
      "Best CV F1 (combined SVM): 0.5827025890088314\n",
      "Validation accuracy (combined, tuned): 0.9443350463474377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     38311\n",
      "           1       0.74      0.47      0.57      3331\n",
      "\n",
      "    accuracy                           0.94     41642\n",
      "   macro avg       0.85      0.73      0.77     41642\n",
      "weighted avg       0.94      0.94      0.94     41642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the parameters and scores for best parameters\n",
    "print(\"Best params (combined SVM):\", grid_both.best_params_)\n",
    "print(\"Best CV F1 (combined SVM):\", grid_both.best_score_)\n",
    "\n",
    "best_svm_both = grid_both.best_estimator_\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_both = best_svm_both.predict(X_val_both)\n",
    "\n",
    "print(\"Validation accuracy (combined, tuned):\", accuracy_score(y_val, y_val_pred_both))\n",
    "print(classification_report(y_val, y_val_pred_both))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
